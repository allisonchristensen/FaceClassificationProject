{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial Classification Project\n",
    "### Allison Christensen Thomas Heysel\n",
    "\n",
    "##### To update the dataset in use, scroll down to the top of code cell 2 and update the input to the load_dataset function. The filename passed in must include 2 files named 'real' and 'fake' to properly function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# Define required objects\n",
    "sift = cv2.SIFT_create()\n",
    "matcher = cv2.BFMatcher()\n",
    "\n",
    "front_face_cascade = cv2.CascadeClassifier()\n",
    "front_face_cascade.load(cv2.samples.findFile('haar_classifiers/haarcascade_frontalface_alt.xml'))\n",
    "side_face_cascade = cv2.CascadeClassifier()\n",
    "side_face_cascade.load(cv2.samples.findFile('haar_classifiers/haarcascade_profileface.xml'))\n",
    "\n",
    "def load_dataset(filename='dataset'):\n",
    "    # Assumes the data is stored in 2 files named dataset/real and dataset/fake\n",
    "    # Returns 2 lists holding the real and fake images seperately \n",
    "    \n",
    "    try:\n",
    "        real_filenames = [filename+'/real/'+f for f in listdir(filename+'/real') if isfile(join(filename+'/real', f))]\n",
    "        fake_filenames = [filename+'/fake/'+f for f in listdir(filename+'/fake') if isfile(join(filename+'/fake', f))]\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error! Cannot read in dataset in the root file {filename}. Please ensure the file exists and \"\n",
    "              f\"contains 2 folders named 'real' and 'fake'.\")\n",
    "        raise e\n",
    "    \n",
    "    real_images = [cv2.cvtColor(cv2.imread(f), cv2.COLOR_BGR2RGB) for f in real_filenames]\n",
    "    fake_images = [cv2.cvtColor(cv2.imread(f), cv2.COLOR_BGR2RGB) for f in fake_filenames]\n",
    "\n",
    "    return real_images, fake_images\n",
    "\n",
    "def equalize_image(img):\n",
    "    img_yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "\n",
    "    # equalize the histogram of the Y channel\n",
    "    img_yuv[:,:,0] = cv2.equalizeHist(img_yuv[:,:,0])\n",
    "\n",
    "    # convert the YUV image back to RGB format\n",
    "    img_output = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2BGR)\n",
    "\n",
    "    return img_output\n",
    "\n",
    "def detect_face(img, side='front'):\n",
    "    # Uses Haar Classifier to detect faces in an images and draw a bounding box around the facial region of interest\n",
    "    # img : an image with a face\n",
    "    # side : a string enum either \"front\" or \"profile\" descibing the type of image\n",
    "    # Return : an image containing only the detected facial ROI for detected faces or [] if no face is detected\n",
    "    \n",
    "    # Convert the image to gray and equalize it. Helps to give better facial detection\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    equilized_gray_img = cv2.equalizeHist(gray_img) \n",
    "    \n",
    "    # Detect the face and create and image of the detected face\n",
    "    if side == 'front':\n",
    "        face = front_face_cascade.detectMultiScale(equilized_gray_img, minSize=(150,150))\n",
    "    else:\n",
    "        face = side_face_cascade.detectMultiScale(equilized_gray_img, minSize=(150,150))\n",
    "    for (x,y,w,h) in face:\n",
    "        img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "        roi_gray = equilized_gray_img[y:y+h, x:x+w]\n",
    "    \n",
    "    # Return the detected face. If no face was detected return an empty array\n",
    "    try:\n",
    "        roi_equalized = equalize_image(roi_color)\n",
    "        return roi_equalized\n",
    "    except UnboundLocalError as e:\n",
    "        return []\n",
    "\n",
    "def feature_matching(img1, img2):\n",
    "    # Performs SIFT feature matching between 2 images and then uses Lowe's Ratio to filter out the bad matches\n",
    "    # img1 : an RGB image\n",
    "    # img2 : an RGB image\n",
    "    # returns : the average of the two ratios  (number of matches / number of keypoints in img1) and\n",
    "    #           (number of matches / number of keypoints in img2)  \n",
    "    \n",
    "    # Regular SIFT\n",
    "    img1_keypoints, img1_descriptors = sift.detectAndCompute(img1, None)\n",
    "    img2_keypoints, img2_descriptors = sift.detectAndCompute(img2, None)\n",
    "    \n",
    "    img1_with_keypoints = cv2.drawKeypoints(img1, img1_keypoints, np.array([]))\n",
    "    img2_with_keypoints = cv2.drawKeypoints(img2, img2_keypoints, np.array([]))\n",
    "    \n",
    "    matches = matcher.knnMatch(img1_descriptors, img2_descriptors, k=2)\n",
    "    matches_img = cv2.drawMatchesKnn(img1, img1_keypoints, img2, img2_keypoints, matches, np.array([]))\n",
    "    \n",
    "    # Lowe's Ratio    \n",
    "    lowes_matches = [[match[0]] for match in matches if (match[0].distance / match[1].distance) < 0.8] \n",
    "    \n",
    "    # Find the ratio\n",
    "    r1 = len(lowes_matches) / len(img1_keypoints)\n",
    "    r2 = len(lowes_matches) / len(img2_keypoints)\n",
    "    avg = (r1 + r2) / 2\n",
    "    \n",
    "    return avg\n",
    "\n",
    "\n",
    "def classification(imgC, imgL, imgR):\n",
    "    # Classifies images as either real or fake\n",
    "    # Takes 3 images as inputs\n",
    "    # Returns True for real faces and False for fake face\n",
    "    \n",
    "    # The confidence measure of our assumption\n",
    "    real_confidence = 0\n",
    "    fake_confidence = 0\n",
    "    \n",
    "    # Real faces will require us to use a profile haar cascade for left and right images. But fake faces will \n",
    "    # require a frontal face cascade. \n",
    "    # Therefore for left and right images if we try a profile cascade and it detects a face it increases our \n",
    "    # confidence that its a real image. If we use a profile cascade and doesn't detect a face, we'll then try a \n",
    "    # frontal cascade. If it detects a face with the frontal cascade it increases our confidence that the image is \n",
    "    # fake.\n",
    "    \n",
    "    left_face = detect_face(imgL, 'profile')\n",
    "    if len(left_face) == 0: # If no face is detected, try frontal cascade\n",
    "        left_face = detect_face(imgL, 'front')\n",
    "        if len(left_face) != 0: # Now a face is detected\n",
    "            fake_confidence = fake_confidence + 1\n",
    "    else:\n",
    "        real_confidence = real_confidence + 1\n",
    "    \n",
    "    right_face = detect_face(imgR, 'profile')\n",
    "    if len(right_face) == 0: # If no face is detected, try frontal cascade\n",
    "        right_face = detect_face(imgL, 'front')\n",
    "        if len(right_face) != 0: # Now a face is detected\n",
    "            fake_confidence = fake_confidence + 1\n",
    "    else:\n",
    "        real_confidence = real_confidence + 1\n",
    "    \n",
    "    center_face = detect_face(imgC, 'front') # center always requires frontal cascade\n",
    "    \n",
    "    # Find matches between left and center and right and center faces\n",
    "    num_pairs = 0\n",
    "    ratio1 = 0 # Ratios represent the number of matches / the number of keypoints\n",
    "    ratio2 = 0\n",
    "    if len(left_face) != 0 and len(center_face) != 0:\n",
    "        num_pairs = num_pairs + 1\n",
    "        ratio1 = feature_matching(left_face, center_face)\n",
    "    \n",
    "    if len(right_face) != 0 and len(center_face) != 0: \n",
    "        num_pairs = num_pairs + 1\n",
    "        ratio2 = feature_matching(right_face, center_face)\n",
    "    \n",
    "    # Calculate the average ratio of keypoint to matches between left and front comparison and right and front \n",
    "    # comparison. If the Haar Cascade was unable to detect faces in 2 or more of the images we cannot make a \n",
    "    # confident classification and deem it is 'Unclassifiable'\n",
    "    try:\n",
    "        avg_ratio = (ratio1 + ratio2) / num_pairs\n",
    "    except ZeroDivisionError:\n",
    "        return \"Unclassifiable\"\n",
    "    \n",
    "    if avg_ratio > 0.2:\n",
    "        fake_confidence = fake_confidence + 1  \n",
    "    else:\n",
    "        real_confidence = real_confidence + 1\n",
    "        \n",
    "    if real_confidence > fake_confidence:\n",
    "        return \"Real\"\n",
    "    else:\n",
    "        return \"Fake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "8  |  0\n",
      "--------\n",
      "0  |  11\n",
      "Number of triplets that were unclassifiable (this occurs if 2 or more of the images cannot detect a face): 5\n",
      "Precision =  1.0\n",
      "Recall =  1.0\n",
      "Runtime:  3.3856539726257324  ms\n"
     ]
    }
   ],
   "source": [
    "##################################### Update dataset used here ###################################################\n",
    "real_images, fake_images = load_dataset('dataset')\n",
    "##################################################################################################################\n",
    "\n",
    "unclassifiable = 0 # Counter of triplets that could not be classified\n",
    "start = time.time() # Start timer\n",
    "\n",
    "# Classify real images \n",
    "true_positive = 0\n",
    "false_negative = 0\n",
    "for i in range(0, len(real_images)-2, 3): \n",
    "    guess = classification(real_images[i], real_images[i + 1], real_images[i + 2])\n",
    "    if guess == \"Real\":\n",
    "        true_positive = true_positive + 1\n",
    "    elif guess == \"Fake\":\n",
    "        false_negative = false_negative + 1\n",
    "    else:\n",
    "        unclassifiable = unclassifiable + 1\n",
    "        \n",
    "# Classify fake images \n",
    "true_negative = 0\n",
    "false_positive = 0\n",
    "for i in range(0, len(fake_images)-2, 3): \n",
    "    guess = classification(fake_images[i], fake_images[i + 1], fake_images[i + 2])\n",
    "    if guess == \"Real\":\n",
    "        false_positive = false_positive + 1\n",
    "    elif guess == \"Fake\":\n",
    "        true_negative = true_negative + 1\n",
    "    else:\n",
    "        unclassifiable = unclassifiable + 1\n",
    "\n",
    "end = time.time() # End timer\n",
    "runtime = end - start\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print(true_negative, ' | ', false_positive)\n",
    "print('--------')\n",
    "print(false_negative, ' | ', true_positive)\n",
    "\n",
    "print(f'Number of triplets that were unclassifiable (this occurs if 2 or more of the images cannot detect'\n",
    "      f' a face): {unclassifiable}')\n",
    "print('Precision = ', true_positive/(true_positive + false_positive))\n",
    "print('Recall = ', true_positive/(true_positive + false_negative))\n",
    "print('Runtime: ', runtime, \" ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
